# Проект для «Викишоп» c BERT
## Описание проекта
Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. 

Нужно обучить модель классифицировать комментарии на позитивные и негативные. В нашем распоряжении набор данных с разметкой о токсичности правок.

Необходимо построить модель со значением метрики качества F1 не меньше 0.75.
## Описание данных
Данные находятся в файле *toxic_comments.csv*. 
Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак.
## План работ
1. Загрузить и подготовить данные.
2. Обучить разные модели.
3. Сделать выводы.
## Итоговой вывод
1. Загрузили данные и подготовили данные:
    * убедились, что нет пропусков и дубликатов
    * лемматизировали данные
    * избавились от ненужных символов с помощью регулярного выражения
    * избавились от неинформативной колонки
2. Обучение моделей:
    * произвели эмбеддинг признаков с помощью готовой модели BERT, обучили модели и получили следующие значения метрики *f1*: 
        * Логистическая регрессия - 0.66
        * Случайный лес - 0.89
        * LightGBM - 0.83
        
        На лучшей модели *Случайный лес* проверили значение метрики f1 на тестовой выборке и получили значение ***f1=0.89***. 
    
    * произвели векторизацию признаков с помощью метрики *TF-IDF*, обучили модели и получили следующие значения метрики *f1*: 
        * Логическая регрессия - 0.74
        * Случайный лес - 0.15
        * LightGBM - 0.76
        
        
        Для лучшей модели *LightGBM* проверили значение метрики f1 на тестовой выборке и получили значение ***f1=0.78*** (задачу получить значение метрики выше 0.75 выполнили). 
        
3. Как итог можно сказать, что модель "Случайный лес", для которой признаки подготовлены с помощью готовой модели **Bert** (которая еще и специально доработана для работ с токсичными комментариями) лучше всего подходит для нашей задачи классификации комментариев на позитивные и негативные. Результат метрики на тестовой выборке ***f1=0.89***, что гораздо выше целевого значения 0.75. 
    
